# 水果识别系统

## 1. 项目概述

本项目旨在构建一个基于深度学习的水果识别系统，通过训练不同类型的卷积神经网络自定义CNN、MobileNetV2、ResNet18）82分类模型，实现对多种水果的准确识别。系统设计包含模型训练、训练结果管理和用户友好的识别应用界面，方便用户选择预训练模型进行图像识别。

**主要功能:**
*   支持三种主流深度学习模型（自定义CNN、MobileNetV2、ResNet18）的训练。
*   自动化训练过程，并保存训练好的模型权重、损失曲线、精度曲线和混淆矩阵。
*   提供一个交互式应用界面，用户可选择不同模型进行实时水果图像识别。
*   代码结构清晰，易于理解和扩展，并包含详细注释。

## 2. 目录结构

本项目的目录结构设计如下，旨在清晰地组织各个功能模块：

```
fruit_recognition_system/
├── models/                     # 模型训练相关文件
│   ├── cnn_trainer.py          # 自定义CNN模型的训练函数
│   ├── mobilenet_trainer.py    # MobileNetV2模型的训练函数
│   ├── resnet_trainer.py       # ResNet18模型的训练函数
│   └── train_main.py           # 主训练脚本，用于调用和协调模型训练
├── results/                    # 训练结果保存文件夹
│   ├── trained_models/         # 保存训练好的模型权重文件（.pth）
│   └── plots/                  # 保存训练过程中的图像（损失图、准确率图、混淆矩阵）和类别名称文件（.json）
└── app/                        # 应用可视化界面相关文件
    ├── cnn_app.py              # CNN模型的识别应用界面
    ├── mobilenet_app.py        # MobileNetV2模型的识别应用界面
    ├── resnet_app.py           # ResNet18模型的识别应用界面
    └── app_main.py             # 应用主入口，提供模型选择和启动功能
```

## 3. 模型设计与配置

本项目对比了三种不同架构的深度学习模型：自定义CNN、MobileNetV2 和 ResNet18。所有模型均使用PyTorch框架实现。

### 3.1 通用配置

所有模型在训练前都进行了以下通用设置：

*   **设备选择**: 自动检测并优先使用CUDA（GPU）进行训练，如果不可用则回退到CPU。
    ```python
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    ```
*   **中文字体支持**: 确保Matplotlib图表中能正确显示中文标签。
    ```python
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    ```

### 3.2 数据预处理和加载

数据集路径：
*   训练集: `D:/fruit/fruitDate/train`
*   测试集/验证集: `D:/fruit/fruitDate/test`

### 3.2.1 数据集详细信息

**数据集类别 (82类)**:
*   耙耙柑
*   白兰瓜
*   白萝卜
*   白心火龙果
*   百香果
*   菠萝
*   菠萝莓
*   菠萝蜜

**数据集组织结构**:
数据集应按照以下结构组织，其中每个类别的图像存放在对应的子文件夹中：
```
fruitDate/
├── train/
│   ├── 耙耙柑/
│   │   ├── image1.jpg
│   │   ├── ...
│   ├── 白兰瓜/
│   │   ├── imageX.jpg
│   │   ├── ...
│   └── ...
└── test/
    ├── 耙耙柑/
    │   ├── imageA.jpg
    │   ├── ...
    ├── 白兰瓜/
    │   ├── imageY.jpg
    │   ├── ...
    └── ...
```

**数据集大小**: 训练集包含10198张图片，测试集包含2389张图片，总计12587张图片。

数据预处理和增强策略：

*   **图像大小调整**: 所有图像统一调整为 `(64, 64)` 或 `(224, 224)`（MobileNetV2 专用）。
*   **数据增强**:
    *   `transforms.RandomHorizontalFlip()`: 随机水平翻转。
    *   `transforms.RandomRotation(10/15)`: 随机旋转10或15度。
    *   `transforms.RandomVerticalFlip()` (MobileNetV2): 随机垂直翻转。
    *   `transforms.RandomResizedCrop(64, scale=(0.8, 1.0))` (MobileNetV2): 随机裁剪。
    *   `transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)` (MobileNetV2): 颜色抖动。
*   **归一化**: 使用ImageNet数据集的均值和标准差进行归一化。
*   **数据集加载**: 使用`torchvision.datasets.ImageFolder`加载数据集，并使用`torch.utils.data.DataLoader`创建数据加载器，支持批量训练和随机打乱。

### 3.3 自定义CNN模型 (cnn_trainer.py)

*   **模型结构**: `SimpleCNN` 类，包含三层卷积层、池化层和两层全连接层。
    *   卷积层1: 32个3x3滤波器。
    *   卷积层2: 64个3x3滤波器。
    *   卷积层3: 128个3x3滤波器。
    *   池化层: MaxPool2d。
    *   全连接层: 将特征展平后连接到512个神经元，再连接到分类输出。
*   **损失函数**: `nn.CrossEntropyLoss()`，用于多类别分类任务。
*   **优化器**: `optim.Adam()`。
    *   学习率 (`lr`): `0.0001`
    *   权重衰减 (`weight_decay`): `0.001`
*   **学习率调度器**: `optim.lr_scheduler.ReduceLROnPlateau()`，当验证准确率在`patience`个epoch内没有提升时，学习率会降低`factor`倍。
    *   模式 (`mode`): `'max'` (监控最大化的指标，如准确率)
    *   因子 (`factor`): `0.1` (学习率降低10倍)
    *   耐心值 (`patience`): `3`
*   **早停策略**: 如果验证准确率在`patience`（`5`）个epoch内没有提升，训练将停止。

### 3.4 MobileNetV2 模型 (mobilenet_trainer.py)

*   **模型结构**: `MobileNetTransferLearning` 类，基于预训练的`mobilenet_v2`进行迁移学习。
    *   `models.mobilenet_v2(pretrained=True)`: 加载在ImageNet上预训练的MobileNetV2模型。
    *   **替换分类器**: 将原始分类器的最后一层替换为适应本项目类别数的全连接层。
*   **损失函数**: `nn.CrossEntropyLoss()`。
*   **优化器**: `optim.SGD()` (随机梯度下降)。
    *   学习率 (`lr`): `0.001`
    *   动量 (`momentum`): `0.9`
    *   权重衰减 (`weight_decay`): `0.0001`
*   **学习率调度器**: `optim.lr_scheduler.ReduceLROnPlateau()`。
    *   模式 (`mode`): `'max'`
    *   因子 (`factor`): `0.1`
    *   耐心值 (`patience`): `5`
*   **早停策略**: 如果验证准确率在`patience`（`10`）个epoch内没有提升，训练将停止。

### 3.5 ResNet18 模型 (resnet_trainer.py)

*   **模型结构**: `ResNetTransferLearning` 类，基于预训练的`resnet18`进行迁移学习。
    *   `models.resnet18(pretrained=True)`: 加载在ImageNet上预训练的ResNet18模型。
    *   **替换全连接层**: 将原始的全连接层替换为适应本项目类别数的全连接层。
*   **损失函数**: `nn.CrossEntropyLoss()`。
*   **优化器**: `optim.Adam()`。
    *   学习率 (`lr`): `0.0001`
    *   权重衰减 (`weight_decay`): `0.001`
*   **学习率调度器**: `optim.lr_scheduler.ReduceLROnPlateau()`。
    *   模式 (`mode`): `'max'`
    *   因子 (`factor`): `0.1`
    *   耐心值 (`patience`): `5`
*   **早停策略**: 如果验证准确率在`patience`（`10`）个epoch内没有提升，训练将停止。

## 4. 训练与评估

### 4.1 训练流程

`train_main.py` 是项目的主训练脚本。它负责：
1.  定义数据集的训练集和测试集路径（验证集）。
2.  定义模型和图表保存的目录。
3.  确保所有必要的保存目录存在。
4.  依次调用 `cnn_trainer.py` 中的 `train_cnn_model`、`mobilenet_trainer.py` 中的 `train_mobilenet_model` 和 `resnet_trainer.py` 中的 `train_resnet_model` 函数，对各个模型进行训练。

**运行训练**:
在项目根目录（`D:fruit`）下执行以下命令：
```bash
python fruit_recognition_system/models/train_main.py
```

### 4.2 损失函数与优化

*   **损失函数**: 所有模型均采用 `nn.CrossEntropyLoss` 作为损失函数。该损失函数适用于多类别分类任务，它结合了 `LogSoftmax` 和 `NLLLoss`。其计算方式是：首先对模型的输出（logits）进行Softmax操作，得到每个类别的概率分布，然后计算预测概率分布与真实标签之间的负对数似然损失。

*   **优化器**:
    *   自定义CNN和ResNet18模型使用 **Adam优化器**。Adam是一种自适应学习率优化算法，结合了RMSprop和Adagrad的优点，适用于处理稀疏梯度和非平稳目标。
    *   MobileNetV2模型使用 **SGD优化器** (随机梯度下降) **加动量**。SGD是基本的优化器，动量项有助于加速梯度下降过程，减少震荡，更快地收敛。

*   **损失计算**: 在每个训练批次中，模型通过前向传播计算预测结果，然后将预测结果和真实标签输入损失函数计算损失值。接着，通过调用 `.backward()` 方法执行反向传播，计算损失相对于模型参数的梯度。最后，优化器通过 `optimizer.step()` 方法更新模型参数。

### 4.3 关键参数设置

以下是可修改的基本参数及其在代码中的位置：

*   **训练轮次 (Epochs)**:
    *   在 `cnn_trainer.py` 中的 `train_cnn_model` 函数中，`num_epochs` 参数。
    *   在 `mobilenet_trainer.py` 中的 `train_mobilenet_model` 函数中，`num_epochs` 参数。
    *   在 `resnet_trainer.py` 中的 `train_resnet_model` 函数中，`num_epochs` 参数。
    *   **修改方式**: 直接修改函数定义中的默认值或在 `train_main.py` 调用时传入新值。

*   **学习率 (Learning Rate)**:
    *   在各自 `_trainer.py` 文件中，优化器定义时的 `lr` 参数。
    *   **修改方式**: 直接修改优化器定义中的 `lr` 值。

*   **批大小 (Batch Size)**:
    *   在各自 `_trainer.py` 文件中，`DataLoader` 定义时的 `batch_size` 参数。
    *   **修改方式**: 直接修改 `DataLoader` 定义中的 `batch_size` 值。

*   **分类数 (Number of Classes)**:
    *   在各自 `_trainer.py` 文件中，`SimpleCNN`、`MobileNetTransferLearning`、`ResNetTransferLearning` 类的 `__init__` 函数的 `num_classes` 参数。这个值是根据数据集自动推断的 `len(train_dataset.classes)`，通常不需要手动修改，除非数据集类别发生变化。
    *   **修改方式**: 确保您的数据集结构正确，类别数将自动匹配。

*   **其他参数**:
    *   **数据增强**: 在各自 `_trainer.py` 文件中的 `transforms.Compose` 部分，可以添加、修改或删除各种数据增强操作。
    *   **优化器参数**: 例如Adam的`weight_decay`，SGD的`momentum`和`weight_decay`。
    *   **早停耐心值**: `patience` 变量。
    *   **学习率调度器参数**: `scheduler` 定义中的 `factor` 和 `patience`。

### 4.4 训练结果保存

*   **模型文件**: 训练好的模型（包括最佳模型和最终模型）将以 `.pth` 格式保存在 `fruit_recognition_system/results/trained_models/` 目录下。文件名格式为 `model_{model_type}_final.pth` 和 `model_{model_type}_best.pth`。
*   **可视化图表**: 训练过程中的损失曲线 (`_loss_curve.png`)、精度曲线 (`_accuracy_curve.png`) 和混淆矩阵 (`_confusion_matrix.png`) 将以 `.png` 格式保存在 `fruit_recognition_system/results/plots/` 目录下。
*   **类别名称文件**: 每个模型训练后，其对应的类别名称将以 `_class_names.json` 格式保存在 `fruit_recognition_system/results/plots/` 目录下。

### 4.5 模型性能比较与分析

**此处已经根据您提供的报告数据和分析进行了填充。**

一、模型准确率对比

| 模型类型      | 最终训练准确率（%） | 最终验证准确率（%） |
| :------------ | :------------------ | :------------------ |
| 自定义 CNN    | 63.42               | 60.65               |
| MobileNetV2   | 71.48               | 74.68               |
| ResNet18      | 98.77               | 92.17               |

**结论：**

*   **最优模型**：ResNet18 在训练集和验证集上表现最佳，验证集准确率达 92.17%，得益于残差网络的深层特征提取能力和迁移学习对预训练特征的有效利用。
*   **次优模型**：MobileNetV2 验证集准确率为 74.68%，在轻量化设计下实现了速度与精度的平衡。
*   **最差模型**：自定义 CNN 性能最低，验证集准确率仅 60.65%，受限于浅层网络结构，难以捕捉复杂水果特征（如果皮纹理、遮挡场景下的细节）。

二、收敛速度对比

**关键观察：**

*   **收敛速度**：
    *   MobileNetV2 收敛最快，约 15 轮损失趋于稳定，验证集准确率达 70%+；
    *   ResNet18 次之，约 25 轮收敛；
    *   自定义 CNN 收敛最慢，且损失曲线波动较大，需 50 轮以上才逐渐平稳。
*   **损失值差异**：
    *   ResNet18 训练损失最低（最终约 0.2），验证损失约 0.8；
    *   MobileNetV2 训练损失约 1.2，验证损失 1.5；
    *   自定义 CNN 训练损失 1.8，验证损失 2.0，反映出模型对复杂特征的拟合能力差异。

三、过拟合 / 欠拟合分析

| 模型类型    | 过拟合 / 欠拟合表现                          | 原因分析                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| :---------- | :------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 自定义 CNN  | 欠拟合：训练 / 验证准确率低且接近，损失未平稳下降。 | 三层卷积结构简单，参数量少（约 1.2M），无法学习水果图像的高层语义特征（如颜色分布、形状组合）。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| MobileNetV2 | 轻微过拟合：训练准确率略低于验证准确率。     | 深度可分离卷积减少计算量，但轻量化设计导致特征表达能力有限，复杂类别区分能力不足；数据增强策略（颜色抖动、随机裁剪）提升了泛化性。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ResNet18    | 无显著过拟合：训练 / 验证准确率差约 6.6%。 | 残差连接缓解梯度消失，迁移学习通过冻结预训练层避免参数震荡，结合早停策略有效控制过拟合。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |

四、混淆矩阵分析

1.  **自定义 CNN**
    *   **典型混淆案例**：
        *   蟠桃 vs 黄桃：误分率 28%，两者颜色（橙黄色）和形状（圆形带尖）高度相似，浅层网络无法捕捉表皮纹理差异（蟠桃表面更粗糙）。
        *   葡萄 - 红 vs 车厘子：误分率 25%，均为深红色圆形小目标，缺乏深层特征提取导致难以区分大小和光泽度。
    *   **结论**：对相似类别和小目标（图像占比 < 5%）识别能力极弱，仅适用于颜色差异显著的简单场景（如西瓜、柠檬）。

2.  **MobileNetV2**
    *   **典型混淆案例**：
        *   山竹 vs 百香果：误分率 19%，两者外壳均为深紫色且表面粗糙，轻量化模型对纹理细节的捕捉能力不足。
        *   哈密瓜 vs 甜瓜 - 伊丽莎白：误分率 17%，网纹哈密瓜与光皮甜瓜的形状和颜色相近，模型难以区分表皮纹理复杂度。
    *   **结论**：对中低复杂度类别表现较好，但在高相似性、高细节需求的类别（如柑橘类）中存在局限性。

3.  **ResNet18**
    *   **典型混淆案例**：
        *   血橙 vs 脐橙：误分率 8%，两者颜色和形状高度相似，依赖果皮细微纹理差异（血橙有深色斑纹），模型对细节特征的提取能力较强，但仍存在少量误判。
        *   青苹果 vs 青柠：误分率 5%，均为青绿色圆形，模型对亮度和果型轮廓的细微差异（苹果更圆润、青柠略扁）识别较精准，但极端光照下可能混淆。
    *   **结论**：凭借深层残差网络和迁移学习，对复杂特征（如遮挡、多水果重叠）的处理能力显著优于其他模型，误分率集中在极相似类别，整体识别鲁棒性最佳。

五、性能差异原因探讨

*   **模型架构影响**：
    *   **ResNet18**：残差块通过跳跃连接实现跨层特征复用，解决深层网络梯度消失问题，适合提取水果图像的多层次特征（从边缘到语义）。
    *   **MobileNetV2**：深度可分离卷积和线性瓶颈层大幅减少计算量，但牺牲了部分特征表达能力，导致复杂场景下精度受限。
    *   **自定义 CNN**：浅层结构仅能学习低层次特征（如边缘、简单纹理），无法应对水果识别中的多尺度、多类别挑战。
*   **优化策略与数据增强**：
    *   **ResNet18** 采用 迁移学习（冻结预训练层 + 微调全连接层），有效利用 ImageNet 通用特征，结合小样本微调快速适配水果数据。
    *   **MobileNetV2** 使用 SGD + 动量优化器和更强的数据增强（如颜色抖动、随机裁剪），提升了模型对光照变化和姿态差异的鲁棒性，但也可能引入轻微过拟合。
    *   **自定义 CNN** 因参数量少，未采用迁移学习，且数据增强策略简单，导致模型泛化能力不足。
*   **硬件与部署场景**：
    *   **ResNet18** 计算量较大（约 11M 参数），适合 GPU 环境下的高精度场景（如果品分拣生产线）；
    *   **MobileNetV2** 参数仅约 3.5M，适合嵌入式设备（如智能货架摄像头）的实时识别需求；
    *   **自定义 CNN** 虽轻量但精度过低，实际应用价值有限。

## 5. 应用可视化

`app_main.py` 是整个水果识别应用的主入口。它提供了一个简洁的用户界面，允许用户选择不同的预训练模型进行图像识别。

**运行应用**:
在项目根目录（`D:fruit`）下执行以下命令：
```bash
python fruit_recognition_system/app/app_main.py
```

**应用功能**:
1.  **模型选择**: 通过下拉菜单选择要使用的模型（CNN、MobileNet、ResNet18）。
2.  **启动识别**: 点击"启动识别应用"按钮，会打开一个新窗口，该窗口是所选模型的独立识别界面。
3.  **图像上传与识别**: 在识别窗口中，用户可以上传本地图片，模型将对图片进行推理并显示预测结果。
4.  **动态类别加载**: 应用会根据训练时保存的类别信息动态加载水果类别名称，确保识别结果的准确性。

## 5. 模型评价

*   **自定义CNN**
    *   **优点**：实现简单，训练速度快，适合较简单的图像数据集。
    *   **缺点**：在复杂任务中可能表现不足，容易过拟合。

*   **ResNet**
    *   **优点**：深层网络结构，强大的特征提取能力，适合大型复杂数据集，较好的泛化能力。
    *   **缺点**：模型复杂度较高，计算资源需求大，推理速度相对较慢。

*   **MobileNet**
    *   **优点**：高效轻量，适合移动端应用，推理速度快且资源占用少，适合大规模部署。
    *   **缺点**：在某些任务上可能会略逊色于较深的网络（如ResNet），尤其在特征复杂的情况下。

## 6. 总结

在选择模型时，需要根据实际应用场景的需求进行权衡。
*   如果处理的是简单的数据集，且计算资源受限，CNN可能是有效的选择。
*   对于中到大型复杂数据集，ResNet由于其深层次结构，能更好地捕捉特征，是较优的选择。

